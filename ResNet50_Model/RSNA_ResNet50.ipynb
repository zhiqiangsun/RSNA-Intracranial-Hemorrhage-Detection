{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from math import ceil, floor\n",
    "import cv2\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    # iterate through all the columns of a dataframe and modify the data type\n",
    "    #   to reduce memory usage.        \n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def import_data(file):\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****The preprocessing of dicom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_dir=\"../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/\"\n",
    "test_images_dir=\"../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_test/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The helper functions, which are used for the image data augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the traning data, stage_1_train_images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_data(train_dir):\n",
    "    train_df=import_data(train_dir)\n",
    "    train_df[\"SubType\"]=train_df[\"ID\"].apply(lambda x: x.rsplit(\"_\",1)[-1])\n",
    "    train_df[\"ID\"]=train_df[\"ID\"].apply(lambda x: x.rsplit(\"_\",1)[0])\n",
    "    train_df.drop_duplicates(inplace=True)\n",
    "    Label=np.reshape(train_df[\"Label\"].values,(-1,6))\n",
    "    train_df=pd.DataFrame(Label,\n",
    "                          columns=list(train_df[\"SubType\"].unique()),\n",
    "                         index=list(train_df[\"ID\"].unique()))\n",
    "    pos_ids=list(train_df[train_df[\"any\"]==1].index)\n",
    "    neg_ids=list(train_df[train_df[\"any\"]==0].index)\n",
    "    random.shuffle(pos_ids)\n",
    "    random.shuffle(neg_ids)\n",
    "    \n",
    "    pl,nl=len(pos_ids),len(neg_ids)\n",
    "    return train_df,pos_ids, neg_ids\n",
    "\n",
    "train_df_dir=\"../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train.csv\"\n",
    "train_df, pos_ids, neg_ids=read_training_data(train_df_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visaulizing the total number of different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height=list(train_df.sum().values)\n",
    "height.append(len(neg_ids))\n",
    "label=list(train_df.columns)\n",
    "label.append(\"none\")\n",
    "plt.figure(figsize=(20,9))\n",
    "plt.bar(x=[i*0.15 for i in range(1,8)],height=height,width=0.1,tick_label=label,color=[\"r\",\"b\"])\n",
    "epidural_ids=list(train_df[train_df[\"epidural\"]==1].index)\n",
    "plt.figure(figsize=(18,9))\n",
    "samples=random.sample(epidural_ids,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the augmentation types for every image in training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function, GenerateAugmentationParameter, which generate randomly the information for every image in image_ids, what kind of augmentations are taken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateAugmentationParameter(aug):\n",
    "    \n",
    "    p=1   \n",
    "    \n",
    "    if aug==\"rotation\":\n",
    "        \n",
    "        p=random.uniform(-60,+60)\n",
    "        \n",
    "    if aug=='scaling':\n",
    "        \n",
    "        p=random.uniform(1.2,1.8)\n",
    "        \n",
    "    if aug=='cropping':\n",
    "        \n",
    "        p=random.uniform(0.1,0.2)\n",
    "        \n",
    "    if aug=='translate':\n",
    "        \n",
    "        x=random.uniform(-0.2,+0.2)\n",
    "        y=random.uniform(-0.2,+0.2)\n",
    "        \n",
    "        p={\"x\":x, \"y\":y}\n",
    "        \n",
    "    return p\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def GenerateAugmentations(image_ids,df):\n",
    "    \n",
    "    augmentations=[\"windowing\", \"flipping\", \"rotation\", \"scaling\", \"cropping\", \"translate\"]\n",
    "    augs={}\n",
    "    \n",
    "    for i in image_ids:\n",
    "    \n",
    "        if df.loc[i,\"epidural\"]==1:\n",
    "            random_aug_types=augmentations\n",
    "        \n",
    "        elif df.loc[i,\"any\"]==1: \n",
    "            random_aug_types=random.sample(augmentations[1:],3)\n",
    "            random_aug_types.append(\"windowing\")\n",
    "        else:    \n",
    "            #random_aug_types=random.sample(augmentations[1:],1)\n",
    "            #random_aug_types.append(\"windowing\")\n",
    "            random_aug_types=[\"windowing\"]\n",
    "\n",
    "        augs[i]={t: GenerateAugmentationParameter(t) for t in random_aug_types}\n",
    "    \n",
    "    return augs\n",
    "    \n",
    "    \n",
    "image_ids=list(train_df.index)\n",
    "augs=GenerateAugmentations(image_ids,train_df)    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for building the ResNet50 model, with ELU activation and l2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from keras.layers import Input\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as backend\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras_applications.imagenet_utils import decode_predictions\n",
    "from keras_applications.imagenet_utils import preprocess_input\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras import regularizers\n",
    "from keras.layers import ELU\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block, reg=None,elu_alpha=0.1):\n",
    "    \n",
    "    filters1, filters2, filters3=filters\n",
    "    if K.image_data_format()=='channels_last':\n",
    "        bn_axis=3\n",
    "    else:\n",
    "        bn_axis=1\n",
    "    conv_name_base='res'+str(stage)+block+'_branch'\n",
    "    bn_name_base='bn'+str(stage)+block+'_branch'    \n",
    "    \n",
    "    x=Conv2D(filters1,\n",
    "             (1,1),\n",
    "             name=conv_name_base+'2a',\n",
    "             kernel_regularizer=reg)(input_tensor)\n",
    "    x=BatchNormalization(axis=bn_axis, name=bn_name_base+'2a')(x)\n",
    "    x=ELU(alpha=elu_alpha)(x)\n",
    "    \n",
    "    \n",
    "    x=Conv2D(filters2, kernel_size, padding='same',\n",
    "             name=conv_name_base+'2b',\n",
    "             kernel_regularizer=reg)(x)\n",
    "    x=BatchNormalization(axis=bn_axis,name=bn_name_base+'2b')(x)\n",
    "    x=ELU(alpha=elu_alpha)(x)\n",
    "    \n",
    "    \n",
    "    x=Conv2D(filters3,(1,1),name=conv_name_base+'2c',\n",
    "            kernel_regularizer=reg)(x)\n",
    "    x=BatchNormalization(axis=bn_axis,\n",
    "                        name=bn_name_base+'2c')(x)\n",
    "    \n",
    "    x=layers.add([x,input_tensor])\n",
    "    x=ELU(alpha=elu_alpha)(x)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "    \n",
    "\n",
    "def conv_block(input_tensor,kernel_size,filters,\n",
    "               stage,block,reg=None,strides=(2,2),elu_alpha=0.1):\n",
    "    \n",
    "    filters1,filters2,filters3=filters\n",
    "    if K.image_data_format()=='channels_last':\n",
    "        bn_axis=3\n",
    "        \n",
    "    else:\n",
    "        bn_axis=1\n",
    "    \n",
    "    conv_name_base='res'+str(stage)+block+'_branch'\n",
    "    bn_name_base='bn'+str(stage)+block+'_branch'\n",
    "    \n",
    "    \n",
    "    x=Conv2D(filters1,(1,1),strides=strides,\n",
    "            name=conv_name_base+'2a',\n",
    "             kernel_regularizer=reg)(input_tensor)\n",
    "    x=BatchNormalization(axis=bn_axis,name=bn_name_base+'2a')(x)\n",
    "    x=ELU(alpha=elu_alpha)(x)\n",
    "    \n",
    "    \n",
    "    x=Conv2D(filters2, kernel_size, padding='same',\n",
    "            name=conv_name_base+'2b',\n",
    "            kernel_regularizer=reg)(x)\n",
    "    x=BatchNormalization(axis=bn_axis,name=bn_name_base+'2b')(x)\n",
    "    x=ELU(alpha=elu_alpha)(x)\n",
    "    \n",
    "    x=Conv2D(filters3,(1,1),name=conv_name_base+'2c',\n",
    "             kernel_regularizer=reg)(x)\n",
    "    x=BatchNormalization(axis=bn_axis,name=bn_name_base+'2c')(x)\n",
    "    \n",
    "    shortcut=Conv2D(filters3,(1,1),strides=strides,\n",
    "                   name=conv_name_base+'1',\n",
    "                   kernel_regularizer=reg)(input_tensor)\n",
    "    shortcut=BatchNormalization(axis=bn_axis,name=bn_name_base+'1')(shortcut)\n",
    "    \n",
    "    x=layers.add([x,shortcut])\n",
    "    x=ELU(alpha=elu_alpha)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def ResNet50(include_top=True,\n",
    "             weights='imagenet',\n",
    "             input_tensor=None,\n",
    "             input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=1000,\n",
    "            reg=None,\n",
    "            elu_alpha=0.1):\n",
    "    \n",
    "    WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "    WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "    \n",
    "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization), `imagenet` '\n",
    "                         '(pre-training on ImageNet), '\n",
    "                         'or the path to the weights file to be loaded.')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=32,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top,\n",
    "                                      weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "            \n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    \n",
    "    \n",
    "    x=ZeroPadding2D((3,3))(img_input)\n",
    "    x=Conv2D(64,(7,7),strides=(2,2),name='conv1',\n",
    "            kernel_regularizer=reg)(x)\n",
    "    x=BatchNormalization(axis=bn_axis,name=\"bn_conv1\")(x)\n",
    "    x=ELU(alpha=elu_alpha)(x)\n",
    "    x=MaxPooling2D((3,3),strides=(2,2))(x)\n",
    "    \n",
    "    x=conv_block(x,3,[64,64,256],stage=2,block='a',strides=(1,1),reg=reg)\n",
    "    x=identity_block(x,3,[64,64,256],stage=2,block='b',reg=reg)\n",
    "    x=identity_block(x,3,[64,64,256],stage=2,block='c',reg=reg)\n",
    "    \n",
    "    x=conv_block(x,3,[128,128,512],stage=3,block='a',reg=reg)\n",
    "    x=identity_block(x,3,[128,128,512],stage=3,block='b',reg=reg)\n",
    "    x=identity_block(x,3,[128,128,512],stage=3,block='c',reg=reg)\n",
    "    x=identity_block(x,3,[128,128,512],stage=3,block='d',reg=reg)\n",
    "    \n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a',reg=reg)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b',reg=reg)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c',reg=reg)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d',reg=reg)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e',reg=reg)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f',reg=reg)\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a',reg=reg)\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b',reg=reg)\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c',reg=reg)\n",
    "\n",
    "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, activation='softmax', name='fc1000')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='resnet50')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models',\n",
    "                                    md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
    "        else:\n",
    "            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models',\n",
    "                                    md5_hash='a268eb855778b3df3c7506639542a6af')\n",
    "        model.load_weights(weights_path,by_name=True)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='avg_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1000')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmentator:\n",
    "    \n",
    "    def __init__(self,IDs,augs,images_dir=train_images_dir,size=(512,512)):\n",
    "        self.IDs=IDs\n",
    "        self.augs=augs\n",
    "        self.images_dir=train_images_dir\n",
    "        self.augmentations={\"windowing\": self.bsb_windowing,\n",
    "                            \"flipping\": self.left_right_flipping,\n",
    "                            \"rotation\": self.random_rotation,\n",
    "                            \"scaling\": self.scaling,\n",
    "                            \"cropping\": self.cropping,\n",
    "                            \"translate\": self.translate}\n",
    "        self.augs=augs\n",
    "        self.size=size\n",
    "    \n",
    "    def get_hu_image(self,img):\n",
    "        img_array=img.pixel_array\n",
    "        img_array=img.RescaleSlope*img_array+img.RescaleIntercept\n",
    "        return img_array\n",
    "\n",
    "    def windowing_with_sigmoid(self,img,center,width,ue=np.log(254)):\n",
    "        #img should be already converted to hu image.\n",
    "        #Rescaling w.r.t center, width\n",
    "        z=ue*2*(img-center)/width\n",
    "        z=np.clip(z,-20,+20)\n",
    "        img=1/(1+np.exp(-z))\n",
    "    \n",
    "        if np.max(img)!=np.min(img):\n",
    "            img=(img-np.min(img))/(np.max(img)-np.min(img))\n",
    "        return img\n",
    "\n",
    "    def bsb_windowing(self,ID,*arg):\n",
    "        #Read the dcm image\n",
    "        img=pydicom.dcmread(self.images_dir+ID+\".dcm\")\n",
    "    \n",
    "        #Get the hu image:\n",
    "        img=self.get_hu_image(img)\n",
    "    \n",
    "        #Get the brain, subdural,bone windowing of the image\n",
    "        brain_img=self.windowing_with_sigmoid(img, 40, 80)\n",
    "        subdural_img=self.windowing_with_sigmoid(img, 80, 200)\n",
    "        bone_img=self.windowing_with_sigmoid(img, 600, 2000)\n",
    "    \n",
    "        #Concatenate them together, each windowing is a channel\n",
    "        bsb_img=np.zeros((brain_img.shape[0],brain_img.shape[1],3))\n",
    "        bsb_img[:,:,0]=brain_img\n",
    "        bsb_img[:,:,1]=subdural_img\n",
    "        bsb_img[:,:,2]=bone_img\n",
    "    \n",
    "        if self.size != (512, 512):\n",
    "           # resize image\n",
    "           bsb_img = cv2.resize(bsb_img, self.size, interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        return bsb_img\n",
    "    \n",
    "    \n",
    "    def left_right_flipping(self,ID,*arg):\n",
    "        img=self.bsb_windowing(ID,self.size)\n",
    "        aug=iaa.flip.Fliplr(1.0)\n",
    "        img=aug.augment_image(img)\n",
    "        return img\n",
    "    \n",
    "    \n",
    "    def random_rotation(self,ID,rotate=None):\n",
    "        #rotate: the angle, read from self.labels or just randomly generated if not labeled.\n",
    "        img=self.bsb_windowing(ID,self.size)\n",
    "        aug=iaa.geometric.Affine(rotate=rotate)\n",
    "        img=aug.augment_image(img)\n",
    "        return img\n",
    "    \n",
    "\n",
    "    def scaling(self, ID, scale=None):\n",
    "        img=self.bsb_windowing(ID,self.size)\n",
    "        aug=iaa.geometric.Affine(scale=scale)\n",
    "        img=aug.augment_image(img)    \n",
    "        return img\n",
    "    \n",
    "    \n",
    "    def cropping(self, ID, percent=None):\n",
    "        img=self.bsb_windowing(ID,self.size)\n",
    "        aug=iaa.size.Crop(percent=percent)\n",
    "        img=aug.augment_image(img)\n",
    "        return img\n",
    "    \n",
    "\n",
    "    def translate(self, ID, translate_percent=None):\n",
    "        img=self.bsb_windowing(ID,self.size)\n",
    "        aug=iaa.geometric.Affine(translate_percent=translate_percent)\n",
    "        img=aug.augment_image(img)\n",
    "        return img\n",
    "    \n",
    "    \n",
    "    def ImageAugmentation(self, ID,aug='windowing'):\n",
    "    \n",
    "        \n",
    "        \n",
    "        parameter=self.augs[ID][aug]\n",
    "        img=self.augmentations[aug](ID, parameter )\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainDataGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, list_IDs,aug_IDs, labels, augmentator, batch_size=1, img_size=(512, 512), \n",
    "                 img_dir=train_images_dir,*args, **kwargs):\n",
    "        self.list_IDs = list_IDs\n",
    "        self.aug_IDs=aug_IDs\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.img_dir = img_dir\n",
    "        self.on_epoch_end()\n",
    "        self.augmentator=augmentator\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(ceil(len(self.aug_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        aug_IDs_temp = [self.aug_IDs[k] for k in indices]\n",
    "        X, Y = self.__data_generation(aug_IDs_temp)\n",
    "        return X, Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.aug_IDs))\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "    def __data_generation(self, aug_IDs_temp):\n",
    "        X = np.empty((self.batch_size, *self.img_size, 3))\n",
    "        Y = np.empty((self.batch_size, 6), dtype=np.float32)\n",
    "        \n",
    "        for i, aug_ids in enumerate(aug_IDs_temp):\n",
    "            X[i,] = self.augmentator.ImageAugmentation(aug_ids[0],aug=aug_ids[1])\n",
    "            Y[i,] = self.labels.loc[aug_ids[0]].values\n",
    "        \n",
    "        return X, Y\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class TestDataGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, list_IDs, labels, batch_size=1, size=(512, 512), \n",
    "                 images_dir=test_images_dir, *args, **kwargs):\n",
    "\n",
    "        self.list_IDs = list_IDs\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.size =size\n",
    "        self.images_dir = images_dir\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "   \n",
    "    \n",
    "    def get_hu_image(self,img):\n",
    "        img_array=img.pixel_array\n",
    "        img_array=img.RescaleSlope*img_array+img.RescaleIntercept\n",
    "        return img_array\n",
    "\n",
    "    def windowing_with_sigmoid(self,img,center,width,ue=np.log(254)):\n",
    "        #img should be already converted to hu image.\n",
    "        #Rescaling w.r.t center, width\n",
    "        z=ue*2*(img-center)/width\n",
    "        z=np.clip(z,-20,+20)\n",
    "        img=1/(1+np.exp(-z))\n",
    "    \n",
    "        if np.max(img)!=np.min(img):\n",
    "            img=(img-np.min(img))/(np.max(img)-np.min(img))\n",
    "        return img\n",
    "\n",
    "    def bsb_windowing(self,ID,*arg):\n",
    "        #Read the dcm image\n",
    "        img=pydicom.dcmread(self.images_dir+ID+\".dcm\")\n",
    "    \n",
    "        #Get the hu image:\n",
    "        img=self.get_hu_image(img)\n",
    "    \n",
    "        #Get the brain, subdural,bone windowing of the image\n",
    "        brain_img=self.windowing_with_sigmoid(img, 40, 80)\n",
    "        subdural_img=self.windowing_with_sigmoid(img, 80, 200)\n",
    "        bone_img=self.windowing_with_sigmoid(img, 600, 2000)\n",
    "    \n",
    "        #Concatenate them together, each windowing is a channel\n",
    "        bsb_img=np.zeros((brain_img.shape[0],brain_img.shape[1],3))\n",
    "        bsb_img[:,:,0]=brain_img\n",
    "        bsb_img[:,:,1]=subdural_img\n",
    "        bsb_img[:,:,2]=bone_img\n",
    "    \n",
    "        if self.size != (512, 512):\n",
    "           # resize image\n",
    "           bsb_img = cv2.resize(bsb_img, self.size, interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        return bsb_img\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return int(ceil(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indices]\n",
    "        X = self.__data_generation(list_IDs_temp)\n",
    "        return X\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.list_IDs))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        X = np.empty((self.batch_size, *self.size, 3))\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            X[i,] = self.bsb_windowing(ID)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def _weighted_log_loss(y_true, y_pred):\n",
    "\n",
    "    \n",
    "    y_pred = keras.backend.clip(y_pred, keras.backend.epsilon(), 1.0-keras.backend.epsilon())\n",
    "    \n",
    "    weights=np.array([1.0,1.0,1.0,1.0,1.0,2.0])/7.0\n",
    "    out = -(         y_true  * keras.backend.log(      y_pred) \n",
    "            +(1.0 - y_true) * keras.backend.log(1.0 - y_pred) )\n",
    "    \n",
    "    return keras.backend.sum(out*weights, axis=-1)\n",
    "\n",
    "\n",
    "class MyDeepModel:\n",
    "    \n",
    "    def __init__(self, input_dims, batch_size=5, learning_rate=1e-3, \n",
    "                 decay_rate=1.0, decay_steps=1, weights=\"imagenet\", l2_reg=0,verbose=1,elu_alpha=0.1):\n",
    "        \n",
    "        self.input_dims = input_dims\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.decay_rate = decay_rate\n",
    "        self.decay_steps = decay_steps\n",
    "        self.weights = weights\n",
    "        self.verbose = verbose\n",
    "        self.l2_reg=l2_reg\n",
    "        self.elu_alpha=elu_alpha\n",
    "        self._build()\n",
    "\n",
    "    def _build(self):\n",
    "        \n",
    "        reg=keras.regularizers.l2(self.l2_reg)\n",
    "        \n",
    "        #We build a ResNet50 model with L2 regularization\n",
    "        ResNetModel=ResNet50(input_tensor=None,include_top=False, weights=self.weights,\n",
    "                               input_shape=(*self.input_dims, 3),\n",
    "                             reg=reg,elu_alpha=self.elu_alpha)\n",
    "        \n",
    "        x=ResNetModel.output\n",
    "        \n",
    "        x = keras.layers.GlobalAveragePooling2D(name='avg_pool_final')(x)\n",
    "\n",
    "        x = keras.layers.Dense(6, activation=\"sigmoid\", name='dense_output')(x)\n",
    "\n",
    "        self.model = keras.models.Model(inputs=ResNetModel.input, outputs=x)\n",
    "\n",
    "        self.model.compile(loss=_weighted_log_loss, optimizer=keras.optimizers.Adam(0.0))\n",
    "\n",
    "        \n",
    "    def fit(self, df, train_idx, aug_ids, augmentator,global_epoch): \n",
    "        self.model.fit_generator(\n",
    "            TrainDataGenerator(\n",
    "                train_idx,\n",
    "                aug_ids, \n",
    "                df.loc[train_idx], \n",
    "                augmentator,\n",
    "                self.batch_size, \n",
    "                self.input_dims,\n",
    "                img_dir=train_images_dir,\n",
    "            ),\n",
    "            verbose=self.verbose,\n",
    "            use_multiprocessing=True,\n",
    "            workers=4,\n",
    "            callbacks=[\n",
    "                keras.callbacks.LearningRateScheduler(\n",
    "                    lambda global_epoch: self.learning_rate * pow(self.decay_rate, floor(global_epoch / self.decay_steps)))\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def predict(self, df, test_idx, img_dir):\n",
    "        predictions = \\\n",
    "          self.model.predict_generator(\n",
    "            TestDataGenerator(\n",
    "                test_idx, \n",
    "                None, \n",
    "                self.batch_size, \n",
    "                self.input_dims, \n",
    "                img_dir\n",
    "            ),\n",
    "            verbose=self.verbose,\n",
    "            use_multiprocessing=True,\n",
    "            workers=4\n",
    "        )\n",
    "        \n",
    "        return predictions[:df.loc[test_idx].shape[0]]\n",
    "        \n",
    "    \n",
    "    def save(self, path):\n",
    "        self.model.save_weights(path)\n",
    "    \n",
    "    def load(self, path,by_name=False):\n",
    "        self.model.load_weights(path,by_name=by_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_testset(filename=\"../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_sample_submission.csv\"):\n",
    "    df=import_data(filename)\n",
    "    df[\"SubType\"]=df[\"ID\"].apply(lambda x: x.rsplit(\"_\",1)[-1])\n",
    "    df[\"ID\"]=df[\"ID\"].apply(lambda x: x.rsplit(\"_\",1)[0])\n",
    "    Label=np.reshape(df[\"Label\"].values,(-1,6))\n",
    "    df=pd.DataFrame(Label,\n",
    "                    columns=list(df[\"SubType\"].unique()),\n",
    "                    index=list(df[\"ID\"].unique()))\n",
    "    \n",
    "    \n",
    "    return df\n",
    "    \n",
    "test_df = read_testset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyDeepModel(input_dims=(256, 256), batch_size=16, learning_rate=1.5e-5, \n",
    "                    decay_rate=1, decay_steps=1, weights=None, l2_reg=0, verbose=2, elu_alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_log_loss_metric(trues, preds): # add 0.2\n",
    "    class_weights = [1.0/7.0, 1.0/7.0, 1.0/7.0, 1.0/7.0, 1.0/7.0, 2.0/7.0]\n",
    "    # higher epsilon than competition metric\n",
    "    epsilon = 1e-7\n",
    "    \n",
    "    preds = np.clip(preds, epsilon, 1-epsilon)\n",
    "    loss_subtypes = trues * np.log(preds) + (1 - trues) * np.log(1 - preds)\n",
    "    loss_weighted = np.sum(loss_subtypes*class_weights,axis=1)\n",
    "\n",
    "    return -loss_weighted.mean()\n",
    "\n",
    "\n",
    "model = MyDeepModel(input_dims=(256, 256), batch_size=16, learning_rate=0.85*(1.5e-5), \n",
    "                    decay_rate=1, decay_steps=1, weights=None, l2_reg=0, verbose=2, elu_alpha=0.1)\n",
    "augmentator=Augmentator(list(train_df.index),augs,size=(256,256))\n",
    "\n",
    "\n",
    "#Training The Model:\n",
    "train_idx=pos_ids[:len(pos_ids)//2]+neg_ids[:len(neg_ids)//2]\n",
    "augmentator=Augmentator(train_idx,augs,size=(256,256))\n",
    "aug_idx=[(idx,j) for idx in subsample_train_idx for j in augs[idx]]\n",
    "model.fit(train_df,train_idx,aug_idx,augmentator,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(test_df, list(test_df.index), test_images_dir)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.iloc[:, :] = prediction\n",
    "test_df.to_csv(\"predition.csv\",index=False)\n",
    "test_df = test_df.stack().reset_index()\n",
    "test_df[\"ID\"]=test_df[\"level_0\"].astype(str)+\"_\"+test_df[\"level_1\"].astype(str)\n",
    "test_df.drop([\"level_0\",\"level_1\"],axis=1,inplace=True)\n",
    "test_df.columns=['ID','Label']\n",
    "test_df.rename({0:\"Label\"},axis=1)\n",
    "test_df.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
