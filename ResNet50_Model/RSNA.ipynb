{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport numpy as np\nimport pandas as pd\nimport pydicom\nimport os\nimport matplotlib.pyplot as plt\nimport collections\nimport random\nfrom tqdm import tqdm_notebook as tqdm\nfrom datetime import datetime\nfrom keras.callbacks import ModelCheckpoint\nfrom math import ceil, floor\nimport cv2\n\n\nimport tensorflow as tf\nimport keras\n\nimport sys\n\n\ndef reduce_mem_usage(df):\n    # iterate through all the columns of a dataframe and modify the data type\n    #   to reduce memory usage.        \n    \n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df\n\n\ndef import_data(file):\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****The preprocessing of dicom images"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_dir=\"../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/\"\ntest_images_dir=\"../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_test/\"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The helper functions, which are used for the image data augmentations."},{"metadata":{"trusted":true},"cell_type":"code","source":"import imgaug as ia\nimport imgaug.augmenters as iaa    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read the traning data, stage_1_train_images."},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_training_data(train_dir):\n    train_df=import_data(train_dir)\n    train_df[\"SubType\"]=train_df[\"ID\"].apply(lambda x: x.rsplit(\"_\",1)[-1])\n    train_df[\"ID\"]=train_df[\"ID\"].apply(lambda x: x.rsplit(\"_\",1)[0])\n    train_df.drop_duplicates(inplace=True)\n    Label=np.reshape(train_df[\"Label\"].values,(-1,6))\n    train_df=pd.DataFrame(Label,\n                          columns=list(train_df[\"SubType\"].unique()),\n                         index=list(train_df[\"ID\"].unique()))\n    pos_ids=list(train_df[train_df[\"any\"]==1].index)\n    neg_ids=list(train_df[train_df[\"any\"]==0].index)\n    #random.shuffle(pos_ids)\n    #random.shuffle(neg_ids)\n    \n    #pl,nl=len(pos_ids),len(neg_ids)\n    #train_idx,valid_idx=pos_ids[:int(0.8*pl)]+neg_ids[:int(0.4*nl)],pos_ids[int(0.8*pl):]+neg_ids[int(0.4*nl):int(0.5*nl)]\n    #return train_df, train_idx, valid_idx\n    return train_df,pos_ids, neg_ids\n\ntrain_df_dir=\"../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train.csv\"\ntrain_df, pos_ids, neg_ids=read_training_data(train_df_dir)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visaulizing the total number of different types."},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"height=list(train_df.sum().values)\nheight.append(len(neg_ids))\nlabel=list(train_df.columns)\nlabel.append(\"none\")\nplt.figure(figsize=(20,9))\nplt.bar(x=[i*0.15 for i in range(1,8)],height=height,width=0.1,tick_label=label,color=[\"r\",\"b\"])\nepidural_ids=list(train_df[train_df[\"epidural\"]==1].index)\nplt.figure(figsize=(18,9))\nsamples=random.sample(epidural_ids,10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We define the augmentation types for every image in training set."},{"metadata":{},"cell_type":"markdown","source":"Helper function, GenerateAugmentationParameter, which generate randomly the information for every image in image_ids, what kind of augmentations are taken. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def GenerateAugmentationParameter(aug):\n    \n    p=1   \n    \n    if aug==\"rotation\":\n        \n        p=random.uniform(-60,+60)\n        \n    if aug=='scaling':\n        \n        p=random.uniform(1.2,1.8)\n        \n    if aug=='cropping':\n        \n        p=random.uniform(0.1,0.2)\n        \n    if aug=='translate':\n        \n        x=random.uniform(-0.2,+0.2)\n        y=random.uniform(-0.2,+0.2)\n        \n        p={\"x\":x, \"y\":y}\n        \n    return p\n        \n    \n    \n\n\ndef GenerateAugmentations(image_ids,df):\n    \n    augmentations=[\"windowing\", \"flipping\", \"rotation\", \"scaling\", \"cropping\", \"translate\"]\n    augs={}\n    \n    for i in image_ids:\n    \n        if df.loc[i,\"epidural\"]==1:\n            random_aug_types=augmentations\n        \n        elif df.loc[i,\"any\"]==1: \n            random_aug_types=random.sample(augmentations[1:],3)\n            random_aug_types.append(\"windowing\")\n        else:    \n            #random_aug_types=random.sample(augmentations[1:],1)\n            #random_aug_types.append(\"windowing\")\n            random_aug_types=[\"windowing\"]\n\n        augs[i]={t: GenerateAugmentationParameter(t) for t in random_aug_types}\n    \n    return augs\n    \n    \nimage_ids=list(train_df.index)\naugs=GenerateAugmentations(image_ids,train_df)    \n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Functions for building the ResNet50 model, with ELU activation and l2 regularization."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport warnings\nfrom keras.layers import Input\nfrom keras import layers\nfrom keras.layers import Dense\nfrom keras.layers import Activation\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers import AveragePooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import BatchNormalization\nfrom keras.models import Model\nfrom keras.preprocessing import image\nimport keras.backend as backend\nimport keras.backend as K\n\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras_applications.imagenet_utils import decode_predictions\nfrom keras_applications.imagenet_utils import preprocess_input\nfrom keras_applications.imagenet_utils import _obtain_input_shape\nfrom keras.engine.topology import get_source_inputs\nfrom keras import regularizers\nfrom keras.layers import ELU\n\ndef identity_block(input_tensor, kernel_size, filters, stage, block, reg=None,elu_alpha=0.1):\n    \n    filters1, filters2, filters3=filters\n    if K.image_data_format()=='channels_last':\n        bn_axis=3\n    else:\n        bn_axis=1\n    conv_name_base='res'+str(stage)+block+'_branch'\n    bn_name_base='bn'+str(stage)+block+'_branch'    \n    \n    x=Conv2D(filters1,\n             (1,1),\n             name=conv_name_base+'2a',\n             kernel_regularizer=reg)(input_tensor)\n    x=BatchNormalization(axis=bn_axis, name=bn_name_base+'2a')(x)\n    x=ELU(alpha=elu_alpha)(x)\n    \n    \n    x=Conv2D(filters2, kernel_size, padding='same',\n             name=conv_name_base+'2b',\n             kernel_regularizer=reg)(x)\n    x=BatchNormalization(axis=bn_axis,name=bn_name_base+'2b')(x)\n    x=ELU(alpha=elu_alpha)(x)\n    \n    \n    x=Conv2D(filters3,(1,1),name=conv_name_base+'2c',\n            kernel_regularizer=reg)(x)\n    x=BatchNormalization(axis=bn_axis,\n                        name=bn_name_base+'2c')(x)\n    \n    x=layers.add([x,input_tensor])\n    x=ELU(alpha=elu_alpha)(x)\n    \n    return x\n    \n    \n\ndef conv_block(input_tensor,kernel_size,filters,\n               stage,block,reg=None,strides=(2,2),elu_alpha=0.1):\n    \n    filters1,filters2,filters3=filters\n    if K.image_data_format()=='channels_last':\n        bn_axis=3\n        \n    else:\n        bn_axis=1\n    \n    conv_name_base='res'+str(stage)+block+'_branch'\n    bn_name_base='bn'+str(stage)+block+'_branch'\n    \n    \n    x=Conv2D(filters1,(1,1),strides=strides,\n            name=conv_name_base+'2a',\n             kernel_regularizer=reg)(input_tensor)\n    x=BatchNormalization(axis=bn_axis,name=bn_name_base+'2a')(x)\n    x=ELU(alpha=elu_alpha)(x)\n    \n    \n    x=Conv2D(filters2, kernel_size, padding='same',\n            name=conv_name_base+'2b',\n            kernel_regularizer=reg)(x)\n    x=BatchNormalization(axis=bn_axis,name=bn_name_base+'2b')(x)\n    x=ELU(alpha=elu_alpha)(x)\n    \n    x=Conv2D(filters3,(1,1),name=conv_name_base+'2c',\n             kernel_regularizer=reg)(x)\n    x=BatchNormalization(axis=bn_axis,name=bn_name_base+'2c')(x)\n    \n    shortcut=Conv2D(filters3,(1,1),strides=strides,\n                   name=conv_name_base+'1',\n                   kernel_regularizer=reg)(input_tensor)\n    shortcut=BatchNormalization(axis=bn_axis,name=bn_name_base+'1')(shortcut)\n    \n    x=layers.add([x,shortcut])\n    x=ELU(alpha=elu_alpha)(x)\n    \n    return x\n\ndef ResNet50(include_top=True,\n             weights='imagenet',\n             input_tensor=None,\n             input_shape=None,\n             pooling=None,\n             classes=1000,\n            reg=None,\n            elu_alpha=0.1):\n    \n    WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n    WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n    \n    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization), `imagenet` '\n                         '(pre-training on ImageNet), '\n                         'or the path to the weights file to be loaded.')\n\n    if weights == 'imagenet' and include_top and classes != 1000:\n        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    # Determine proper input shape\n    input_shape = _obtain_input_shape(input_shape,\n                                      default_size=224,\n                                      min_size=32,\n                                      data_format=K.image_data_format(),\n                                      require_flatten=include_top,\n                                      weights=weights)\n\n    if input_tensor is None:\n        img_input = layers.Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n            \n    if backend.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    \n    \n    x=ZeroPadding2D((3,3))(img_input)\n    x=Conv2D(64,(7,7),strides=(2,2),name='conv1',\n            kernel_regularizer=reg)(x)\n    x=BatchNormalization(axis=bn_axis,name=\"bn_conv1\")(x)\n    x=ELU(alpha=elu_alpha)(x)\n    x=MaxPooling2D((3,3),strides=(2,2))(x)\n    \n    x=conv_block(x,3,[64,64,256],stage=2,block='a',strides=(1,1),reg=reg)\n    x=identity_block(x,3,[64,64,256],stage=2,block='b',reg=reg)\n    x=identity_block(x,3,[64,64,256],stage=2,block='c',reg=reg)\n    \n    x=conv_block(x,3,[128,128,512],stage=3,block='a',reg=reg)\n    x=identity_block(x,3,[128,128,512],stage=3,block='b',reg=reg)\n    x=identity_block(x,3,[128,128,512],stage=3,block='c',reg=reg)\n    x=identity_block(x,3,[128,128,512],stage=3,block='d',reg=reg)\n    \n    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a',reg=reg)\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b',reg=reg)\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c',reg=reg)\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d',reg=reg)\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e',reg=reg)\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f',reg=reg)\n\n    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a',reg=reg)\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b',reg=reg)\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c',reg=reg)\n\n    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n\n    if include_top:\n        x = Flatten()(x)\n        x = Dense(classes, activation='softmax', name='fc1000')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    # Create model.\n    model = Model(inputs, x, name='resnet50')\n\n    # load weights\n    if weights == 'imagenet':\n        if include_top:\n            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n                                    WEIGHTS_PATH,\n                                    cache_subdir='models',\n                                    md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n        else:\n            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                                    WEIGHTS_PATH_NO_TOP,\n                                    cache_subdir='models',\n                                    md5_hash='a268eb855778b3df3c7506639542a6af')\n        model.load_weights(weights_path,by_name=True)\n        if K.backend() == 'theano':\n            layer_utils.convert_all_kernels_in_model(model)\n\n        if K.image_data_format() == 'channels_first':\n            if include_top:\n                maxpool = model.get_layer(name='avg_pool')\n                shape = maxpool.output_shape[1:]\n                dense = model.get_layer(name='fc1000')\n                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~/.keras/keras.json.')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Augmentator:\n    \n    def __init__(self,IDs,augs,images_dir=train_images_dir,size=(512,512)):\n        self.IDs=IDs\n        self.augs=augs\n        self.images_dir=train_images_dir\n        self.augmentations={\"windowing\": self.bsb_windowing,\n                            \"flipping\": self.left_right_flipping,\n                            \"rotation\": self.random_rotation,\n                            \"scaling\": self.scaling,\n                            \"cropping\": self.cropping,\n                            \"translate\": self.translate}\n        self.augs=augs\n        self.size=size\n    \n    def get_hu_image(self,img):\n        img_array=img.pixel_array\n        img_array=img.RescaleSlope*img_array+img.RescaleIntercept\n        return img_array\n\n    def windowing_with_sigmoid(self,img,center,width,ue=np.log(254)):\n        #img should be already converted to hu image.\n        #Rescaling w.r.t center, width\n        z=ue*2*(img-center)/width\n        z=np.clip(z,-20,+20)\n        img=1/(1+np.exp(-z))\n    \n        if np.max(img)!=np.min(img):\n            img=(img-np.min(img))/(np.max(img)-np.min(img))\n        return img\n\n    def bsb_windowing(self,ID,*arg):\n        #Read the dcm image\n        img=pydicom.dcmread(self.images_dir+ID+\".dcm\")\n    \n        #Get the hu image:\n        img=self.get_hu_image(img)\n    \n        #Get the brain, subdural,bone windowing of the image\n        brain_img=self.windowing_with_sigmoid(img, 40, 80)\n        subdural_img=self.windowing_with_sigmoid(img, 80, 200)\n        bone_img=self.windowing_with_sigmoid(img, 600, 2000)\n    \n        #Concatenate them together, each windowing is a channel\n        bsb_img=np.zeros((brain_img.shape[0],brain_img.shape[1],3))\n        bsb_img[:,:,0]=brain_img\n        bsb_img[:,:,1]=subdural_img\n        bsb_img[:,:,2]=bone_img\n    \n        if self.size != (512, 512):\n           # resize image\n           bsb_img = cv2.resize(bsb_img, self.size, interpolation=cv2.INTER_LINEAR)\n        \n        return bsb_img\n    \n    \n    def left_right_flipping(self,ID,*arg):\n        img=self.bsb_windowing(ID,self.size)\n        aug=iaa.flip.Fliplr(1.0)\n        img=aug.augment_image(img)\n        return img\n    \n    \n    def random_rotation(self,ID,rotate=None):\n        #rotate: the angle, read from self.labels or just randomly generated if not labeled.\n        img=self.bsb_windowing(ID,self.size)\n        aug=iaa.geometric.Affine(rotate=rotate)\n        img=aug.augment_image(img)\n        return img\n    \n\n    def scaling(self, ID, scale=None):\n        img=self.bsb_windowing(ID,self.size)\n        aug=iaa.geometric.Affine(scale=scale)\n        img=aug.augment_image(img)    \n        return img\n    \n    \n    def cropping(self, ID, percent=None):\n        img=self.bsb_windowing(ID,self.size)\n        aug=iaa.size.Crop(percent=percent)\n        img=aug.augment_image(img)\n        return img\n    \n\n    def translate(self, ID, translate_percent=None):\n        img=self.bsb_windowing(ID,self.size)\n        aug=iaa.geometric.Affine(translate_percent=translate_percent)\n        img=aug.augment_image(img)\n        return img\n    \n    \n    def ImageAugmentation(self, ID,aug='windowing'):\n    \n        \n        \n        parameter=self.augs[ID][aug]\n        img=self.augmentations[aug](ID, parameter )\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass TrainDataGenerator(keras.utils.Sequence):\n\n    def __init__(self, list_IDs,aug_IDs, labels, augmentator, batch_size=1, img_size=(512, 512), \n                 img_dir=train_images_dir,*args, **kwargs):\n        self.list_IDs = list_IDs\n        self.aug_IDs=aug_IDs\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.img_dir = img_dir\n        self.on_epoch_end()\n        self.augmentator=augmentator\n    \n    \n    def __len__(self):\n        return int(ceil(len(self.aug_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n        aug_IDs_temp = [self.aug_IDs[k] for k in indices]\n        X, Y = self.__data_generation(aug_IDs_temp)\n        return X, Y\n\n    def on_epoch_end(self):\n        self.indices = np.arange(len(self.aug_IDs))\n        np.random.shuffle(self.indices)\n\n    def __data_generation(self, aug_IDs_temp):\n        X = np.empty((self.batch_size, *self.img_size, 3))\n        Y = np.empty((self.batch_size, 6), dtype=np.float32)\n        \n        for i, aug_ids in enumerate(aug_IDs_temp):\n            X[i,] = self.augmentator.ImageAugmentation(aug_ids[0],aug=aug_ids[1])\n            Y[i,] = self.labels.loc[aug_ids[0]].values\n        \n        return X, Y\n    \n    \n    \n    \n    \n    \n    \nclass TestDataGenerator(keras.utils.Sequence):\n\n    def __init__(self, list_IDs, labels, batch_size=1, size=(512, 512), \n                 images_dir=test_images_dir, *args, **kwargs):\n\n        self.list_IDs = list_IDs\n        self.labels = labels\n        self.batch_size = batch_size\n        self.size =size\n        self.images_dir = images_dir\n        self.on_epoch_end()\n        \n   \n    \n    def get_hu_image(self,img):\n        img_array=img.pixel_array\n        img_array=img.RescaleSlope*img_array+img.RescaleIntercept\n        return img_array\n\n    def windowing_with_sigmoid(self,img,center,width,ue=np.log(254)):\n        #img should be already converted to hu image.\n        #Rescaling w.r.t center, width\n        z=ue*2*(img-center)/width\n        z=np.clip(z,-20,+20)\n        img=1/(1+np.exp(-z))\n    \n        if np.max(img)!=np.min(img):\n            img=(img-np.min(img))/(np.max(img)-np.min(img))\n        return img\n\n    def bsb_windowing(self,ID,*arg):\n        #Read the dcm image\n        img=pydicom.dcmread(self.images_dir+ID+\".dcm\")\n    \n        #Get the hu image:\n        img=self.get_hu_image(img)\n    \n        #Get the brain, subdural,bone windowing of the image\n        brain_img=self.windowing_with_sigmoid(img, 40, 80)\n        subdural_img=self.windowing_with_sigmoid(img, 80, 200)\n        bone_img=self.windowing_with_sigmoid(img, 600, 2000)\n    \n        #Concatenate them together, each windowing is a channel\n        bsb_img=np.zeros((brain_img.shape[0],brain_img.shape[1],3))\n        bsb_img[:,:,0]=brain_img\n        bsb_img[:,:,1]=subdural_img\n        bsb_img[:,:,2]=bone_img\n    \n        if self.size != (512, 512):\n           # resize image\n           bsb_img = cv2.resize(bsb_img, self.size, interpolation=cv2.INTER_LINEAR)\n        \n        return bsb_img\n        \n\n    def __len__(self):\n        return int(ceil(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indices]\n        X = self.__data_generation(list_IDs_temp)\n        return X\n\n    def on_epoch_end(self):\n        self.indices = np.arange(len(self.list_IDs))\n\n    def __data_generation(self, list_IDs_temp):\n        X = np.empty((self.batch_size, *self.size, 3))\n        \n        for i, ID in enumerate(list_IDs_temp):\n            X[i,] = self.bsb_windowing(ID)\n        \n        return X","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def _weighted_log_loss(y_true, y_pred):\n\n    \n    y_pred = keras.backend.clip(y_pred, keras.backend.epsilon(), 1.0-keras.backend.epsilon())\n    \n    weights=np.array([1.0,1.0,1.0,1.0,1.0,2.0])/7.0\n    out = -(         y_true  * keras.backend.log(      y_pred) \n            +(1.0 - y_true) * keras.backend.log(1.0 - y_pred) )\n    \n    return keras.backend.sum(out*weights, axis=-1)\n\n\nclass MyDeepModel:\n    \n    def __init__(self, input_dims, batch_size=5, learning_rate=1e-3, \n                 decay_rate=1.0, decay_steps=1, weights=\"imagenet\", l2_reg=0,verbose=1,elu_alpha=0.1):\n        \n        self.input_dims = input_dims\n        self.batch_size = batch_size\n        self.learning_rate = learning_rate\n        self.decay_rate = decay_rate\n        self.decay_steps = decay_steps\n        self.weights = weights\n        self.verbose = verbose\n        self.l2_reg=l2_reg\n        self.elu_alpha=elu_alpha\n        self._build()\n\n    def _build(self):\n        \n        reg=keras.regularizers.l2(self.l2_reg)\n        \n        #We build a ResNet50 model with L2 regularization\n        ResNetModel=ResNet50(input_tensor=None,include_top=False, weights=self.weights,\n                               input_shape=(*self.input_dims, 3),\n                             reg=reg,elu_alpha=self.elu_alpha)\n        \n        x=ResNetModel.output\n        \n        x = keras.layers.GlobalAveragePooling2D(name='avg_pool_final')(x)\n\n        x = keras.layers.Dense(6, activation=\"sigmoid\", name='dense_output')(x)\n\n        self.model = keras.models.Model(inputs=ResNetModel.input, outputs=x)\n\n        self.model.compile(loss=_weighted_log_loss, optimizer=keras.optimizers.Adam(0.0))\n        \n    \"\"\"TrainDataGenerator(\n                train_idx,\n                aug_ids, \n                df.loc[train_idx], \n                augmentator,\n                self.batch_size, \n                self.input_dims,\n                img_dir=train_images_dir,\n            ),\"\"\"\n    \n    def fit(self, df, train_idx, aug_ids, augmentator,global_epoch): \n        self.model.fit_generator(\n            TrainDataGenerator(\n                train_idx,\n                aug_ids, \n                df.loc[train_idx], \n                augmentator,\n                self.batch_size, \n                self.input_dims,\n                img_dir=train_images_dir,\n            ),\n            verbose=self.verbose,\n            use_multiprocessing=True,\n            workers=4,\n            callbacks=[\n                keras.callbacks.LearningRateScheduler(\n                    lambda global_epoch: self.learning_rate * pow(self.decay_rate, floor(global_epoch / self.decay_steps)))\n            ]\n        )\n    \n    def predict(self, df, test_idx, img_dir):\n        predictions = \\\n          self.model.predict_generator(\n            TestDataGenerator(\n                test_idx, \n                None, \n                self.batch_size, \n                self.input_dims, \n                img_dir\n            ),\n            verbose=self.verbose,\n            use_multiprocessing=True,\n            workers=4\n        )\n        \n        return predictions[:df.loc[test_idx].shape[0]]\n        \n    \n    def save(self, path):\n        self.model.save_weights(path)\n    \n    def load(self, path,by_name=False):\n        self.model.load_weights(path,by_name=by_name)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_testset(filename=\"../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_sample_submission.csv\"):\n    df=import_data(filename)\n    df[\"SubType\"]=df[\"ID\"].apply(lambda x: x.rsplit(\"_\",1)[-1])\n    df[\"ID\"]=df[\"ID\"].apply(lambda x: x.rsplit(\"_\",1)[0])\n    Label=np.reshape(df[\"Label\"].values,(-1,6))\n    df=pd.DataFrame(Label,\n                    columns=list(df[\"SubType\"].unique()),\n                    index=list(df[\"ID\"].unique()))\n    \n    \n    return df\n    \ntest_df = read_testset()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\"\"\"\nTrainDataGenerator(\n                train_idx,\n                aug_ids, \n                df.loc[train_idx], \n                augmentator,\n                self.batch_size, \n                self.input_dims,\n                img_dir,\n            )\nlist_IDs, aug_IDs, labels, augmentator, batch_size=1, img_size=(512, 512)            \n\"\"\"\n\"\"\"\naugmentator=Augmentator(list(train_df.index),augs,size=(256,256))\nrandom.shuffle(pos_ids)\nrandom.shuffle(neg_ids)\ntrain_df=train_df.loc[pos_ids+neg_ids]\ntrain_df.to_csv(\"train_df.csv\")\naug_df=pd.DataFrame(list(augs.values()),index=list(augs.keys()))\naug_df.to_csv(\"augmentation_parameters.csv\")\n\"\"\"\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ndef weighted_log_loss_metric(trues, preds): # add 0.2\n    class_weights = [1.0/7.0, 1.0/7.0, 1.0/7.0, 1.0/7.0, 1.0/7.0, 2.0/7.0]\n    # higher epsilon than competition metric\n    epsilon = 1e-7\n    \n    preds = np.clip(preds, epsilon, 1-epsilon)\n    loss_subtypes = trues * np.log(preds) + (1 - trues) * np.log(1 - preds)\n    loss_weighted = np.sum(loss_subtypes*class_weights,axis=1)\n\n    return -loss_weighted.mean()\n\n#def run(model, df, pos_ids, neg_ids, epochs):\n    \n    #valid_predictions = []\n    #test_predictions = []\n    #valid_losses=[]\n\nmodel = MyDeepModel(input_dims=(256, 256), batch_size=16, learning_rate=1.5e-5, \n                    decay_rate=0.7, decay_steps=1, weights=\"imagenet\", l2_reg=0, verbose=2, elu_alpha=0.1)\n                        \nvalid_idx=pos_ids[:len(pos_ids)//10]+neg_ids[:len(neg_ids)//10]\ntrain_pos_idx,train_neg_idx=pos_ids[len(pos_ids)//10:2*(len(pos_ids)//10)],neg_ids[len(neg_ids)//10:2*(len(neg_ids)//10)]\ntrain_idx=train_pos_idx+train_neg_idx\ntrain_aug_idx=[(idx,j) for idx in train_idx for j in augs[idx]]\n\nfor global_epoch in range(10):\n                        \n    model.fit(train_df,train_idx,train_aug_idx,augmentator,global_epoch)\n    model.save(\"ResNet50\"+\"_\"+str(global_epoch)+\".h5\")\n    \n    if global_epoch>5:\n        prediction=model.predict(train_df, valid_idx, _TRAIN_IMAGES)    \n        #valid_predictions.append(model.predict(df, valid_idx, _TRAIN_IMAGES))\n        valid_loss=weighted_log_loss_metric(train_df.loc[valid_idx].values, \n                                         prediction)\n        #valid_losses.append(valid_loss)\n        print(\"validation loss:\"+str(valid_loss))    \n\"\"\"\n\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ntrain_df=import_data(\"../input/kernel3c163cba40/train_df.csv\")\ntrain_df.rename({\"Unnamed: 0\": \"ID\"},axis=\"columns\",inplace=True)\ntrain_df.set_index(\"ID\",inplace=True)\npos_ids=list(train_df[train_df[\"any\"]==1].index)\nneg_ids=list(train_df[train_df[\"any\"]==0].index)\n\naug_df=import_data(\"../input/kernel3c163cba40/augmentation_parameters.csv\")\naug_df.rename({\"Unnamed: 0\": \"ID\"},axis=\"columns\",inplace=True)\naug_df.set_index(\"ID\",inplace=True)\n\naugs_notnull=aug_df.notnull()\naugs={ID: {c: aug_df.loc[ID,c] for c in ['cropping','windowing','rotation','scaling','flipping'] if augs_notnull.loc[ID,c]==True} for ID in aug_df.index}\n\ntranslate=aug_df.translate[aug_df.translate.notnull()]\nfor i in translate.index:\n    x=float(translate[i].split()[1][:-1])\n    y=float(translate[i].split()[3][:-1])\n    augs[i]['translate']={'x':x,'y':y}\n    \ndel augs_notnull, aug_df\n\ndef weighted_log_loss_metric(trues, preds): # add 0.2\n    class_weights = [1.0/7.0, 1.0/7.0, 1.0/7.0, 1.0/7.0, 1.0/7.0, 2.0/7.0]\n    # higher epsilon than competition metric\n    epsilon = 1e-7\n    \n    preds = np.clip(preds, epsilon, 1-epsilon)\n    loss_subtypes = trues * np.log(preds) + (1 - trues) * np.log(1 - preds)\n    loss_weighted = np.sum(loss_subtypes*class_weights,axis=1)\n\n    return -loss_weighted.mean()\n\n#def run(model, df, pos_ids, neg_ids, epochs):\n    \n    #valid_predictions = []\n    #test_predictions = []\n    #valid_losses=[]\n\nmodel = MyDeepModel(input_dims=(256, 256), batch_size=16, learning_rate=1.5e-5, \n                    decay_rate=1, decay_steps=1, weights=None, l2_reg=0, verbose=2, elu_alpha=0.1)\n\nmodel.load(\"../input/kernel3c163cba40/ResNet50_4.h5\",by_name=True)\n           \nvalid_idx=pos_ids[:len(pos_ids)//10]+neg_ids[:len(pos_ids)//10]\ntrain_idx_pos,train_idx_neg=pos_ids[len(pos_ids)//10:],neg_ids[len(neg_ids)//10:]\naugmentator=Augmentator(list(train_df.index),augs,size=(256,256))\n\nfor global_epoch in range(2,8):\n        \n    subsample_pos_idx=train_idx_pos[(len(train_idx_pos)//8)*global_epoch:(len(train_idx_pos)//8)*(global_epoch+1)]\n    subsample_neg_idx=train_idx_neg[(len(train_idx_neg)//16)*global_epoch:(len(train_idx_neg)//16)*(global_epoch+1)]\n                \n    subsample_train_idx=subsample_pos_idx+subsample_neg_idx\n    \n    \n    subsample_aug_idx=[(idx,j) for idx in subsample_train_idx for j in augs[idx]]\n    \n    model.fit(train_df,subsample_train_idx,subsample_aug_idx,augmentator,1)\n    \n    if global_epoch%2==1:\n        \n        model.save(\"ResNet50\"+\"_\"+str(global_epoch)+\".h5\")\n        \nprediction=model.predict(train_df, valid_idx, _TRAIN_IMAGES)    \n        #valid_predictions.append(model.predict(df, valid_idx, _TRAIN_IMAGES))\nvalid_loss=weighted_log_loss_metric(train_df.loc[valid_idx].values, \n                                         prediction)\n        #valid_losses.append(valid_loss)\n        \nprint(valid_loss)\n\n\"\"\"\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MyDeepModel(input_dims=(256, 256), batch_size=16, learning_rate=1.5e-5, \n                    decay_rate=1, decay_steps=1, weights=None, l2_reg=0, verbose=2, elu_alpha=0.1)\nmodel.load(\"../input/kernel3c163cba40/ResNet50_4.h5\",by_name=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction=model.predict(test_df, list(test_df.index), test_images_dir)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.iloc[:, :] = prediction\ntest_df.to_csv(\"predition.csv\",index=False)\ntest_df = test_df.stack().reset_index()\ntest_df[\"ID\"]=test_df[\"level_0\"].astype(str)+\"_\"+test_df[\"level_1\"].astype(str)\ntest_df.drop([\"level_0\",\"level_1\"],axis=1,inplace=True)\ntest_df.columns=['ID','Label']\ntest_df.rename({0:\"Label\"},axis=1)\ntest_df.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=import_data(\"../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2=import","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}